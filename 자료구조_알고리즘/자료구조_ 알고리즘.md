자료구조
- 컴퓨터의 메모리 자원은 매우 한정적인데 반해 처리해야 할 데이터는 무수히 많을 수 있다
- 메모리 공간을 효율적으로 사용해야 하는데 이때 필요한 것이 자료 구조
- 모든 목적에 맞는 자료구조는 없다
- 따라서 각 자료구조가 갖는 장점과 한계를 잘 아는 것이 중요
- 추상자료형을 프로그래밍 언어로 구현한 것

알고리즘
- 어떤 문제를 해결하기 위해 정해진 일련의 절차나 방법을 공식화한 형태로 표현한 것
- 문제풀이에 필요한 계산절차 또는 처리과정의 순서
- 같은 지식수준을 가진 사람이라면 그 알고리즘을 보고 누구나 같은 결과를 낼 수 있어야 한다
-> 보통 자료 구조가 선택되면 적용할 알고리즘은 거의 명확해짐
- 자료 구조와 알고리즘은 밀접한 관계


추상자료형(Abstract Data Type, ADT)
- 자료형의 구현으로부터 분리된 자료형
- 자료나 연산이 무엇인지 정의하나, 어떻게 구현할 것인지는 정의 하지 않음
- 데이터 정의 + 연산 정의
- 구현을 외부에 모르게하고, 외부에 간단한 인터페이스만을 공개 -> 정보은닉의 개념
- 구현으로부터 명세의 분리
- 대표적으로 스택, 큐 -> 실제 구현은 배열이나 연결리스트로 구현

자료 구조의 선택 → 효율적인 알고리즘의 선택
넓은 의미에서 자료구조 + 알고리즘(+a) = 프로그램

빅오 표기법
- 일반적으로 알고리즘의 시간복잡도를 나타내는데 사용
- 점근적 상한에 대한 표기법
- 알고리즘이 해당 차수이거나 그보다 낮은 차수의 시간복잡도를 가진다는 의미
- 빅오 표기법은 알고리즘 최악의 실행 시간을 표기
- 빅오 표기법은 최소 차수 함수로 표기될때만 의미가 있음
- 대부분의 알고리즘은 시간과 공간이 트레이드오프관계

선형 자료구조(Linear Data Structure)
- 데이터 요소를 순차적으로 연결하는 자료구조
- 배열, 연결리스트, 스택, 큐, 힙, 해시
Array(배열)
- 동일한 타입의 데이터들을 저장
- 고정된 크기를 가짐
- 배열은 논리적 순서와 물리적 순서가 일치 -> 인접한 메모리 위치에 연이어 저장
- Random Access를 지원(인덱스로 직접 접근 가능) ->  n 번째 요소에 접근하려면 시작 주소에 n * sizeof(데이터 타입)를 더하면 바로 접근 가능
- 다양한 정렬 알고리즘에서 사용 -> 배열을 일정한 순서로 저장할 수 있기 때문에 arr[0] = '가' arr[1] = '나'
시간 복잡도
검색
- 인덱스 접근(직접 접근) : O(1)
- 인덱스를 모르는 경우(순차 접근): O(n)
삽입 & 삭제
- 삽입 & 삭제 시 길이가 고정되어있기 때문에, 한 칸씩 밀어야하는 과정이 필요 : O(n)

장점 
- 인덱스를 이용한 빠른 접근
- 연속된 메모리 공간 사용 - 메모리 관리가 간단하고, 캐시 효율성이 높음 ?? 

단점
- 항목을 전체 컨트롤할 수 없음, 항목 단위별로 수행해야 함

Linked List(연결 리스트)
- 배열의 추가/삭제 연산에 대한 비효율성을 극복하고자 등장한 데이터 구조
- 각 데이터 노드가 연결된 순차적 구조(Sequential Access를 지원)
- 새로운 요소 추가시 런타임에 메모리를 할당(동적으로 메모리할당)
- 단일 연결 리스트, 이중 연결 리스트, 원형 연결 리스트 등이 있음
- 인덱스나 위치와 같은 물리적 배치를 사용하지 않고 참조 시스템(다음 노드를 가르키는 포인터 또는 주소)을 사용
- 노드 = key(데이터), next(다음 노드를 가리키는 포인터)
- 첫 번째 요소 : Head, 마지막 요소 : Tail
- ex) Alt + Tab을 사용하여 프로그램 간 전환, 갤러리
시간 복잡도
검색
- 첫 노드부터 순차적으로 접근 : O(n)
삽입 & 삭제
- 동적으로 메모리를 관리 하므로,  삽입 & 삭제시 해당 부분만 변경 됨 : O(1)


장점
- 동적인 데이터 추가/삭제에 유리 ->  동적으로 크기를 조절할 수 있어 메모리를 효율적으로 사용 -> 불필요한 공간 낭비x
- 삽입/삭제의 효율성 ->> 특정 위치에 요소를 삽입, 삭제할 때 다른 요소들을 이동시키지 않아도 됨

Stack(스택)
- 순서가 보존되는 선형 데이터 구조
- 가장 최근에 넣은 데이터부터 처리 LIFO(후입 선출)
- 배열(크기 고정)또는 연결리스트(크기 가변)로 구현
- 
- ex) 실행취소(undo), 재귀 프로그래밍에서 함수 호출 구현
장점
- 후입선출의 특성을 활용한 간단한 알고리즘 구현 용이
- 재귀 호출상황에서 유용하게 사용

시간 복잡도
검색
- 처음부터 순차적으로 접근 : O(n)
삽입 & 삭제
- Top 위치에서 데이터를 삽입 & 삭제 : O(1)


Queue(큐)
- 순서가 보존되는 선형 데이터 구조
- 가장 오래된 데이터를 먼저 처리 FIFO
- 배열과 연결리스트로 구현
- ex) 멀티스레딩에서의 스레드 관리, 대기열 시스템

시간 복잡도
검색
- 처음부터 순차적으로 접근 : O(n)
삽입 & 삭제
- Front(Head), Rear(Tail)위치에서 데이터를 삽입 & 삭제 : O(1)
- 배열 큐 일때 삽입: O(n)

덱
- 큐의 Front(Head), Rear(Tail)위치에서 모두 삽입 삭제가 가능한 큐
시간 복잡도
삽입/삭제
- O(1)


탐색
- 테이블 또는 집합에서 원하는 탐색키를 가진 레코드를 찾는 작업

맵
- key-value 쌍으로 데이터를 저장하는 탐색을 위한 자료구조
- 키는 일반적으로 유일하지만 동일할 수 도있음- (영단어에 여러뜻이 있는 것처럼)
- 맵을 가장 효율적으로 구현할 수 있는 방법은 해싱 O(1)만에 찾을 수 있음, 배열과 연결리스트는 탐색속도가 느림

순차 탐색(Sequential Search)
- 일반적으로 정렬되지 않은 배열의 요소들을 처음부터 마지막까지 하나씩 검사하여 원하는 레코드를 찾는 방법
시간복잡도
- O(n)

이진 탐색(Binary Search)
- 정렬된 배열에서 중앙에 있는 값과 찾는 값과 비교하여 왼쪽부분 배열에 있는지 오른쪽 배열에 있는지 확인는 과정을 반복하는 방법
시간 복잡도
- 이진 탐색 각 단계에서 탐색 범위가 반으로 줄어드므로, O(logn)

색인 순차 탐색(Indexed Sequential Search)
- 인덱스 테이블을 이용해 탐색의 효율을 높인 방법으로, 인덱스 테이블은 주 자료 리스트에서 일정 간격으로 발췌한 자료를 가지고 있음
- 이러한 인덱스 테이블로 특정 값이 해당하는 일정구간에 속하는지 검사하고, 해당 구간에서 순차적으로 탐색 수행을 함
시간 복잡도
- 인덱스 테이블 크기 m, 입력크기가 n일때 O((m+(n/m))

보간 탐색(Interpolation Search)
- 탐색 값이 존재할 위치를 예측하여 탐색하는 방법으로 이진 탐색과 유사한 접근 방식 사용
- 탐색 값과 위치는 비례한다는 가정에서 탐색 위치를 결정할 때 찾고자 하는 키 값이 있는 곳에 접근하도록 가중치를 주는 방법
- 직선의 방정식을 통해 유도됨 pos = low + ((value - arr[low]) * (high - low)) / (arr[high] - arr[low])
시간복잡도
- 평균적으로 선형적으로 균등하게 분포될시  O(log(log n)), 최악의 경우 입력 배열 값들이 균일하지 않게 분포되었을때,   O(n)
- 일반적으로 이진 탐색보다는 빠름

해시 탐색
- 해싱은 키값에 산술적인 연산을 적용하여 항목이 지정될 위치인 인덱스를 직접 계산 하는 방식
- 키 값에서 항목의 위치를 계산하는 함수를 해시 함수
- 해시 함수에 의해 계산된 위치에 레코드를 저장한 표를 해시 테이블
-  해시 함수는 탐색키를 입력받아 해시주소를 계산하는데, 삽입, 삭제, 탐색 연산 모두 이 주소에서 이루어짐
- 해시테이블은 M개의 버킷으로 이루어지는 테이블이고, 하나의 버킷은 여러 개의 슬롯을 가지는데 하나의 슬롯에는 하나의 레코드가 저장됨
- 키가 입력되면 해시 함수로 연산하여 해시 주소가 되어, 이를 인덱스로 사용하여 해시 테이블에 있는 항목에 접근
- 버킷의 수가 고정되므로 경우에 따라 서로 다른키가 해시함수에 의해 같은 주소로 계산되는 상황을 충돌이라고 함
- 

Hash table(해시 테이블)
- 해시된 값을 색인(index)으로 삼아 키(key)와 데이터(value)를 저장하는 자료구조
- 데이터의 크기에 관계없이 삽입 및 검색에 매우 효율적 
- 테이블 안의 작은 그룹인 버킷에 키/값 쌍을 저장
- 해시 충돌이  자주 일어 날 수 있음
- ex) DB 인덱스 구현, 사용자 로그인 인증-> 패스워드를 해시해서 db에저장된 해시값과 같은지 비교, set 데이터 구조 구현
시간 복잡도
- 최선의 경우O(1), 최악의 경우-충돌발생, 모든값이 하나의 위치로 충돌될때 O(n)

Hash table 종류
Direct Address Table
- 데이터를 배열의 인덱스로 사용하여 저장하는 방식으로 동작
- 탐색,삽입,삭제 연산 모두 O(1)
- 데이터의 크기가 매우 크거나 데이터가 sparse(희소한) 경우에는 적합하지 않음 -	> 배열의 크기가 매우 크거나, 배열의 일부분만 사용되고 나머지 부분은 빈 공간이 되기 때문에

Hash Table
- 해시된 해시값을 인덱스로 변환하여 키 값과 데이터를 저장하는 테이블
적재율
- 해시 테이블의 크기 대비, 키의 개수
- (키의 개수)/ (해시테이블 크기)
- Direct Address Table은 1이하, 적재율이 1 초과인 해시 테이블의 경우는 반드시 충돌이 발생
- 충돌X-> 탐색, 삽입, 삭제 연산 모두 O(1), 충돌 O -> 탐색, 삭제 연산 O(n)
- 해시함수로 도출된 값들이 같은 경우가 빈번하게 발생하게 되므로 잦은 충돌로 이어지게 됨

충돌 해결
해시 테이블 구조 개선
체이닝(Chaining)
- 충돌이 발생했을 때 하나의 위치에 여러 개의 항목을 저장할 수 있도록 해시 테이블의 구조를 변경
- 연결리스트로 구현
- 탐색과 삭제, 삽입의 경우 평균 O(1)가 걸림
선형 탐사(Open Addressing)
- 충돌 발생시 다른 주소를 찾아 저장하는 방법
- 삽입: 계산한 해시 값에 대한 인덱스가 이미 차있는 경우 다음 인덱스로 이동하면서 비어있는 곳에 저장 -> 비어 있는 곳을 찾는 것 = 탐사
- 탐색: 계산한 해시 값에 대한 인덱스부터 검사하며 탐사를 해나가는데 이 때 “삭제” 표시가 있는 부분은 지나감 즉, 한번도 사용안된 버킷을 만나야 탐색 중단
- 삭제: 탐색을 통해 해당 값을 찾고 삭제한 뒤 “삭제” 표시
- 해시 충돌이 발생할 경우 검색 연산 시간이 증가하여 시간 복잡도가 O(n)으로 나타남

Open Addressing의 3가지 충돌 처리기법
선형탐사(Linear Probing)
- 바로 인접한 인덱스에 데이터를 삽입
- 데이터가 밀집되는 군집화(Clustering) 문제가 발생하고 이로인해 탐색, 삭제가 느림

제곱탐사(Quadratic Probing)
- 충돌 발생시, 새로운 위치를 찾기위해 1의 제곱, 2의 제곱, 3의 제곱을 더해가며 탐사를 하는 방식
- 선형탐사에 비해 더 폭넓게 탐사하기 때문에 탐색,삭제 효율적
- 마찬가지로 클러스터링 문제가 발생할수 있음-> 동일한 위치 충돌 발생시 똑같은 위치를 찾아가기 때문에

=> 선형탐사, 제곱탐사는 해시함수 값이 같으면 결국 동일한 위치를 탐사하게 되는 문제 발생

이중해싱(Double Hashing)
- 선형탐사와 제곱탐사에서 발생하는 클러스터링 문제를 모두 피하기 위해 도입된 것
- 탐색키를 참조하여 더해지는 값을 결정, 해시함수값이 같아도 탐색키가 다르면 서로 다른 탐색 순서를 가짐
- 처음 해시함수로는 해시값을 찾기 위해 사용하고 두번째 해시함수는 충돌이 발생했을 때 탐사폭을 계산하기 위해 사용되는 방식

해시 함수 개선
- 충돌이 적어야 하며 , 계산이 빨라야함
- 해시함수 값이 해시테이블의 주소 내에서 고르게 분포되어야 함

제산 함수
- 나머지 연산자를 사용하는 함수
- 해시 테이블의 크기를 알고 있는 경우 사용 가능
- 해시 테이블 크기로 데이터를 나눈 나머지를 해시값으로 사용하는 방법
- 나누는 값(해시 테이블 크기)은 근처값인 소수를 사용

폴딩 함수
- 주로 탐색키가 해시 테이블의 크기보다 더 큰 정수일 경우에 사용
- 탐색키를 몇개의 부분으로 나누어 이를 더한 값을 해시주소로 사용

중간 제곱함수
- 탐색키를 제곱한 다음, 중간의 몇비트를 취해서 해시 주소를 생성
- 탐색키를 제곱한 값의 중간 비트들은 보통 비교적 고르게 분산됨

비트 추출 방법
- 해시 테이블의 크기가 M=2^k 일때, 탐색키를 이진수로 간주하여 임의의 위치의 k개의 비트를 해시주소로 사용하는 것
- 아주 간단하지만 해시 주소의 집중 현상이 일어날 가능성이 높음

숫자 분석 방법
- 숫자로 구성된 키에서 각 위치마다 수의 특징을 미리 알고 있을때 유용
- 키의 각각의 위치에 있는 숫자 중에서 편중되지 않는 수들을 해시 테이블의 크기에 적합한 만큼 조합하여 해시 주소로 사용
- 학번 20172880의 앞4자리는 편중되어있으므로 나머지 수를 조합하여 해시 주소로 사용하는 방법

탐색키가 문자열인 경우
- 각 문자에 정수르 대응시켜 바꿈
- 아스키코드나 유니코드 값을 그대로 사용
비선형 자료구조(Non-Linear Data Structure)
- 데이터 요소를 비순차적으로 연결
-  한 데이터 요소에서 여러 데이터 요소로 연결되기도 함
- 그래프, 트리

Graph(그래프)
- 노드 사이에 엣지가 있는 collection = (여러 개의 데이터를 모아서 저장하고, 관리하는 자료구조)
	- 배열과 달리, 컬렉션은 동적으로 크기를 조절할 수 있으며, 더 이상 필요하지 않은 데이터는 자동으로 해제
	- 자주 사용되는 연산을 제공
	- 배열과 달리, 다양한 자료형의 데이터를 저장
	- Java에서는 ArrayList, LinkedList, HashSet, TreeMap 등
- directed(방향)- 단방향, undirected(무방향)- 양방향 이 존재
- 트리에 사이클이 존재할때의 형태
- ex) 소셜 미디어 네트워크를 나타내는데 사용, 검색 엔진에 의해 웹 페이지(노드) 및 링크(엣지)를 나타내는데 사용, GPS에서 위치와 경로를 나타내는데 사용- 그래프 알고리즘으로 경로 최적화,  GPS 좌표 - 노드
장점
- 다양한 관계 표현 가능 - 현실세계의 복잡한 관계를 모델링하기 적합
- 유연한 연결성 - 그래프는 노드와 간선을 구성되어 있어, 다양한 형태의 연결성을 표현 가능
- 네트워크 및 경로 탐색 - 네트워크 모델링이나 최단 경로, 최소 스패닝 트리 등의 문제를 효율적으로 해결

시간 복잡도
두 정점을 연결하는 간선의 존재 여부
- 인접 행렬의 경우 고유 인덱스로 바로 접근 가능 : O(1) 
- 인접 리스트의 경우 정점 차수 만큼 시간이 필요 O(degree(v))
정점의 차수
- 인접행렬 :O(n) - 인접배열의 정점 햄에 있는 값 모두 더함
- 인접 리스트의 경우 정점 차수 만큼 시간이 필요 O(degree(v))
모든 간선의 수
- 인접행렬 전체 조사 -O(n^2)
- 인접리스트 - O(n+e) n = 정점, e= 간선


추가/삭제 (Insert/Delete)
추가의 경우 노드/정점이나 엣지 모두 O(1)
삭제의 경우에는 노드/정점의 경우 특정 노드/정점을 찾는 시간과 그와 연결된 엣지를 삭제해야 하므로 O(N+E)/O(V+E) 엣지의 경우 특정 엣지를 찾는 시간이 소요되므로 O(E)

Tree(트리)
- 그래프가 계층적 구조를 가진 형태 ,사이클 X
- 최상위 노드(루트)를 가지고 있음
- 상위 노드 = 부모(Parent) 노드, 하위 노드 = 자식(Child) 노드
- ex) 
Binary Trees(이진트리),
- 각 노드가 최대 2개의 자식 노드를 가지는 트리 구조
Binary Search Tree(이진 검색 트리),
- 이진 트리의 한 종류로, 각 노드의 값이 그 왼쪽 서브트리의 모든 값보다 크고, 그 오른쪽 서브트리의 모든 값보다 작음
Heap(힙) 
Tree 장점
- 계층 적인 구조
- 빠른 검색 및 삽입
- 이진 검색 트리(Binary Search Tree)는 데이터를 정렬된 상태로 저장하므로, 정렬된 데이터를 검색하는 데에 효율적
- 데이터의 동적 크기 조절


Heap(힙) 
- 완전 이진 트리의 일종으로,우선순위 큐를 위해 만들어진 자료구조
- 반 정렬 상태를 유지
- 부모 노드가 자식 노드보다 우선순위가 높은 구조
- 힙은 일반적으로 배열을 이용하여 구현- 첫번째 인덱스0은 사용하지않음- 프로그램 구현을 쉽게하기위해 1부터시작
	- 왼쪽 자식 인덱스 = 부모 인덱스x2 , 오른쪽 자식 인덱스 = 부모 인덱스 x2 +1, 부모 인덱스 = 자식인덱스/2
- 최대 힙(Max Heap)과 최소 힙(Min Heap) 두종류가 있음
- 최대 힙에서는 부모 노드 키 값이 자식 노드의 키값과 같은 완전 이진트리, 최소힙은 부등호방향만 바뀜
- 이진탐색트리와 달리 중복된 값을 허용
- ex)
힙 삽입연산 - 업힙
- 입력 배열의 끝에서부터 시작하여 부모 노드와 자식 노드를 비교하면서 큰 값을 부모 노드로 이동시키는 과정을 반복
힙 삭제연산
- 루트노드를 삭제하고, 마지막 노드를 루트 노드에 위치시킨 후 다시 정렬시킴 - 다운힙
힙 정렬
- n개의 요소를 하나씩 힙에 삽입 후 힙에서, n번에 걸쳐 하나씩 요소들을 삭제하고 출력
- 시간복잡도 = nlog2(n)+ nlog2(n) =O(nlog2(n))
- 전체 자료에서 가장 큰 값 몇개만 필요할때 매우 유용함
우선순위 큐
- 데이터들이 우선순위를 가지고 있고, 이를 기준으로 높은 우선순위의 데이터가 먼저 처리되는 자료구조
장점
- 우선순위 큐를 구현하는 데에 효과적으로 사용
- 동적 메모리 할당하므로 데이터의 동적 크기 조절이 가능

시간복잡도
추가/삭제
- O(log2(n))

재귀호출(순환)
- 자기 자신을 호출하여 문제를 해결하는 기법
시간 복잡도
- 팩토리얼- 순환 - O(n), 반복- O(n) - 비효율적임- 단순히 보기편하게 하기위해 사용
- 거듭제곱 - 순환 -O(logn), 반복 -O(n)
- 

깊이 우선 탐색(depth first serch, DFS)
- 시작 정점에서부터 인접한 정점으로 깊이 탐색을 진행하는 방식
시간 복잡도
- 모든 간선을 조사하므로
- 인접리스트 O(n+e)
- 인접 행렬O(n^2)

너비 우선 탐색(breadth first search, BFS)
- 시작 정점으로부터 인접한 정점을 먼저 방문하고 멀리 떨어져 있는 정점을 나중에 방문하는 순회 방법
시간 복잡도
- 인접리스트 O(n+e)
- 인접 행렬 O(n^2)

최소비용 신장트리(Mnimum Spanning Tree, MST)
- 간선들의 가중치 합이 최소인 신장트리
- 신장트리는 그래프의 내부의 모든 노드가 연결 되어있고, 사이클이 없는 트리
- 구하는 방법으로 Kruskal과 Prim 알고리즘이 있음

Kruskal의 MST 알고리즘
- 탐욕적인 방법 기법을 사용
- 각 단계에서 사이클을 이루지 않는 최소 비용 간선을 선택하는 과정을 n-1개 간선을 가질때까지 반복하여 그래프의 모든 정점을 최소비용으로 연결하는 최적 해답을 구함
시간복잡도
- 간선들을 정렬하는 시간에 좌우됨
- O(|E|log2|E|)

Prim의 MST 알고리즘
- 하나의 정점에서부터 시작하여 트리를 단계적으로 확장해나가는 방법
- 처음에는 시작 정점만 트리에 포함되고, 그다음 트리에 인접한 정점들 중 간선의 가중치가 가장 작은 정점을 선택하여 트리가 n-1개 간선을 가질때까지트리를 확장해 나감
시간 복잡도
- O(n^2)
- 간선의 개수가 적은 희박한 그래프는 Kruskal 알고리즘이 유리
- 간선이 매우 많은 그래프의 경우 Prim 알고리즘이 유리

최단경로
- 가중치 그래프에서 정점 u와 정점 v를 연결하는 경로 중에서 간선들의 가중치 합이 최소가 되는 경로
- 다익스트라, 플로이드 알고리즘이 존재

다익스트라(Dijkstra) 알고리즘
- 하나의 시작 정점에서 다른 모든 정점까지의 최단경로
- 가장 짧은 경로부터 탐색하여, 최단 거리가 확정된 노드를 방문하고, 그와 연결된 노드의 최단 거리를 업데이트하는 방식
- 탐욕 알고리즘의 일종
시간 복잡도
- 그래프에 n개의 정점일때, , 매번 아직 최단 경로가 결정되지 않은 정점들 중에서 최소 거리를 갖는 정점을 찾기 위해 O(n),그리고 이를 모든 정점에 대해서 반복하므로 O(n^2)
- 힙 자료구조를 사용하면 개선할 수 있음

플로이드(Flyod) 알고리즘
- 모든 정점에서 다른 모든 정점까지의 최단 경로
- 음의 가중치를 가진 간선도 처리가능
시간 복잡도
- 그래프에 n개의 정점일때, O(n^3)

정렬 알고리즘

정렬 장소에 따른 분류
내부 정렬
- 정렬하기 전에 모든 데이터가 메인메모리에 올라와 있는 정렬
외부 정렬
- 기억 장치에 대부분의 데이터가 있고 일부만 메모리에 있는 상태에서 정렬을 하는 방법
- 대용량 자료를 정렬하는데 적합

구현복잡도와 알고리즘 효율성에 따른 분류
- 단순하지만 비효율적인 방법: 삽입,선택, 버블 정렬등
- 복잡하지만 효울적인 방법: 퀵, 힙, 병합, 기수 정렬 등

안정성에 따른 분류
- 안정성이란 입력데이터에 동일한 키 값을 갖는 레코드가 여러개 존재할 경우, 정렬 후에도 이들의 상대적인 위치가 바뀌지 않는 것
- 안정성을 충족하는 정렬은 삽입, 버블, 병합정렬 등이 존재

선택 정렬(배열)
- 최소값을 반복적으로 선택해 앞으로 옮기는 알고리즘
- 최솟값이 선택되면 배옆 앞부분부터 정렬되지 않은 값과 교환
- 그리디 알고리즘으로 분류
시간 복잡도
- 첫번째 요소와 나머지 요소의 최소값을 비교하여 교환 그다음 반복, n-1 n-2 .., o(n^2)
- 안정성 만족x

삽입 정렬(배열)
- 정렬이 안된 부분의 숫자를 정렬된 부분의 적절한 위치를 찾아 삽입하는 과정을 반복
- 안정정렬
- 그리디 알고리즘으로 분류
시간 복잡도
- 배열 역순시, 삽입될 위치를 찾기 위해, 1, 2, n-2 , n-1번 반복, 즉 O(n^2)
- 정렬되어있을시 효율적임

버블정렬(배열)
- 인접한 2개의 레코드를 비교하여, 크기순으로 서로 교환하여 정렬하는 알고리즘
- 교환이 이루어지지 않을때까지 반복
- 그리디 알고리즘으로 분류
시간 복잡도
-  배열이 역순일시, 가장 큰 값이 맨 오른쪽으로 가기위해 n-1, 그다음 값은 오른쪽 끝에서 두번째자리까지 n-2번으로 반복,즉  O(n^2)

셸 정렬
- 삽입정렬을 개선한 알고리즘으로, 간격을 줄여가며 간격이 1이 될때까지 일정한 간격만큼 요소를 그룹화하여 삽입정렬을 수행하는 방식
- 불안정정렬에 속함
- 그리디 알고리즘으로 분류
시간복잡도
- 최악의 경우 O(n^2), 평균적으로는 O(n^1.5)로 삽입정렬 보다 대체적으로 빠름


병합 정렬(Merge Sort, 또는 합병 정렬)
- 하나의 리스트를 두개의 균등한 크기로 분할하고 더이상 분할되지 않을때까지 분할한 후 부분 리스트를 정렬 후  두 리스트를 합하여 전체가 정렬된 리스트를 만드는 방법
- 분할정복 알고리즘으로 분류
- 안정적인 정렬 방법
시간복잡도
- 병합단계에서만 비교연산, 이동연산이 발생하므로, 총 병합단계는 log2(n)이고, 비교 연산은 각 단계마다 요소를 전부 읽고 비교하기 때문에 n
따라서, O(nlogn)

퀵 정렬(Quick Sort)
- 배열안의 한 요소를 피벗으로 설정 후 피벗보다 작은 요소들은 모두 피벗의 왼쪽으로 옮기고, 피벗보다 큰 요소들은 모두 피벗의 오른쪽으로 옮김, 이러한 과정을  피벗 왼쪽과 오른쪽에서 반복적으로 수행하여 더이상 리스트를 분해할 수 없을 때까지 반복
- 분할정복 알고리즘으로 분류
시간복잡도
- 최악의 경우: 피벗이 항상 최대값이나 최소값일 경우, 한쪽만 n-개의 요소를 포함하게되어 분할이 반복되면 총 O(n)이 걸리고, 비교하는 연산이 O(n)이므로, O(n^2)
- 평균: 피벗이 중앙값이나 균등한 값을 가질경우 피벗 중심으로 각 배열들의 크기가 거의 같으므로, 분할작업에서O(logn) 비교연산에서 O(n)이므로,  O(nlog2n)


힙 정렬
- 힙정렬은 선택정렬을 개선한 알고리즘으로,  n개의 요소를 하나씩 힙에 삽입 후 힙에서, n번에 걸쳐 하나씩 요소들을 삭제하고 출력
- 그리디 알고리즘으로 분류
시간복잡도
- 힙은 완전이진트리이므로 높이는 log2n 따라서, 삽입, 삭제 연산또한 logn, n개 삽입 삭제시 2nlog2n 이므로, 
O(nlogn)임
- 최악, 최선, 평균 모두 O(nlogn)

기수 정렬(radix sort)
- 어떤 비교연산도 실행하지 않고 데이터를 정렬할수 있는 알고리즘
- 기수는 숫자의 자리수를 의미하고, 다단계로 정렬하며, 단계의 수는 데이터의 자리수 개수와 일치
- 가장 낮은 자리수부터 정렬을 시작하고, 큐로 구현하여 자리수의 상대적인 순서를 유지
- 실수나 한글, 영어로 이루어진 키값을 정렬할때 많은 버킷이 필요하므로 적용이 어려움
시간 복잡도
- n개의 요소와 각 요소의 자리수가 d일때, O(dn), d는 컴퓨터에서 크기가 제한되므로, n에 비하여 매우 작은수 이므로 O(n)으로도 볼 수 있음



분할정복(Divide & Conquer)
- 어떤 문제를 더 작은 동일한 문제들로 분해하여 작은 문제를 해결하고 다시 병합하여 상위 문제의 답을 얻는 방식

동적계획법(Dynamic Programming)
- 하나의 큰 문제를 해결하기 위해서 큰 문제를 작은 문제로 나누어, 작은 문제로부터 계산된 결과값를 이용하여 전체문제를 해결하는 알고리즘 
 
탐욕 알고리즘(Greedy Algorithm)
- 최적의 해에 가까운 값을 구하기 위해 사용되는 알고리즘
- 매순간 최선의/최적의 선택을하여 최종적인 값을 구하는 방식

백트래킹(Backtracking)
- 퇴각검색이라고 불리며, 제약조건 만족 문제(Constraint Satisfaction Problem)에서 해를 찾기 위한 전략
- 해를 찾기위해서 어떤 후보군을 대상으로 제약조건을 체크하다가 해당 후보군이 제약조건을 만족할 수 없다고 판단되면, 그 즉시 backtrack(다시는 해당 후보군을 체크하지 않을 것을 표시)한 후, 다른 후보군으로 넘어가는 방식으로 최적의 해를 찾는 전략
https://bnzn2426.tistory.com/115

https://re-code-cord.tistory.com/entry/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0-%EB%8C%80%ED%91%9C%EC%A0%81%EC%9D%B8-%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0-%EC%A0%95%EB%A6%AC
두근두근 자료구조
https://devraphy.tistory.com/89
